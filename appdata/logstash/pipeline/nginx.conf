# Logstash -> Elasticsearch

input {
  file {
    path => "/logstash_dir/nginx/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  # Extract log file contents into variables
  dissect {
    mapping => { "message" => "%{ip} - - [%{ts} %{+ts}] %{HTTPMethod} %{targetDownload} %{HTTPProtocol} %{HTTPStatus}" }
  }

  # Update elasticsearch import data with the actual download date
  date {
    match => [ "ts", "dd/MMM/yyyy:HH:mm:ss Z" ]
  }

  # TODO: this isn't working...
  # Get geo coordinates based on the IP address
  geoip {
    source => [ "ip" ]
    add_tag => [ "IP_Geo_Decoded"]
  }

  # Identify filename and filetype
  ruby {
    code => "event.set('targetDownloadFilename', event.get('targetDownload').split('/').last); event.set('targetDownloadFiletype', event.get('targetDownloadFilename').split('.').last)"
  }

  # Add fingerprinting to avoid duplicates
  fingerprint {
    source => "message"
    target => "[@metadata][fingerprint]"
    method => "MURMUR3"
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    user => "${ELASTICSEARCH_USERNAME:elastic}"
    password => "${ELASTICSEARCH_PASSWORD:MagicPassword}"
    index => "nginx-%{+yyyy-MM-dd}"
    document_type => "access_logs"
    document_id => "%{[@metadata][fingerprint]}"
  }
}
